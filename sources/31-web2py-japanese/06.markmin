## データベース抽象化レイヤ
``DAL``:inxx

### 依存関係

web2pyは、データベース抽象化層(DAL)を備えています。これは、Pythonオブジェクトを、クエリやテーブル、レコードなどのデーターベース・オブジェクトに対応付けするAPIです。DAL は、データベース・バックエンド固有の方言を用いてSQLをリアルタイムで動的に生成します。そのため、開発者はSQLコードを書く必要がなく、また、異 なるSQL方言を学ぶ必要もありません(SQLという言葉は総称的に用いています)。そして、アプリケーションは異なるタイプのデータベース間でポータブ ルになります。こ の文書の執筆時点で、サポートされているデータベースは、SQLite (Pythonに備わっています。したがってweb2pyにも備わっています)、PostgreSQL、MySQL、Oracle、MSSQL、 FireBird、DB2、Informix、Ingres、(部分的に) the Google App Engine (GAE)です。GAEは、第11章で具体的事例として扱います。

Windowsのバイナリ配布は、SQLiteとMySQLとともに、すぐに利用できます。 Macのバイナリ配布は、SQLiteとともにすぐに利用できます。他のデータベースバックエンドを使うには、ソース配布から実行し、バックエンドに必要な適切なドライバをインストールしてください。``database drivers``:inxx

適切なドライバをインストールしたら、web2pyをソースから起動してください。web2pyはドライバを見つけることになります。以下はドライバのリストです：

----------
database | driver (source)
SQLite | sqlite3 or pysqlite2 or zxJDBC ``zxjdbc``:cite  (on Jython)
PostgreSQL | psycopg2 ``psycopg2``:cite  or zxJDBC ``zxjdbc``:cite  (on Jython)
MySQL | MySQLdb ``mysqldb``:cite
Oracle | cx_Oracle ``cxoracle``:cite
MSSQL | pyodbc ``pyodbc``:cite
FireBird | kinterbasdb ``kinterbasdb``:cite
DB2 | pyodbc ``pyodbc``:cite
Informix | informixdb ``informixdb``:cite
Ingres | ingresdbi ``ingresdbi``:cite
---------

web2pyは、DALを構成する次のクラスを定義しています：

**DAL**は、データベース接続を表します。例:
``
db = DAL('sqlite://storage.db')
``:code

``define_table``:inxx
**Table**はデータベースのテーブルを表します。Tableを直接インスタンスかすることはなく、代わりに、``DAL.define_table``によってインスタンス化します。
``
db.define_table('mytable', Field('myfield'))
``:code

Tableの中で最も重要なメソッドは以下のものです：

``.insert``, ``.truncate``, ``.drop``, and ``.import_from_csv_file``.

``Field``:inxx
**Field**はデータベースのフィールドを表します。インスタンス化して、``DAL.define_table``へ引数として渡すことができます。

``Rows``:inxx
**DAL Rows** ``Row``:inxxはデータベースの選択によって返されるオブジェクトです。``Row``の行からなるリストとして考えることができます：
``
rows = db(db.mytable.myfield!=None).select()
``:code

``Row``:inxx
**Row**はフィールドの値を保持します。
``
for row in rows:
    print row.myfield
``:code

``Query``:inxx
**Query**はSQLの"where"句を表現するオブジェクトです：
``
myquery = (db.mytable.myfield != None) | (db.mytable.myfield > 'A')
``:code

``Set``:inxx
**Set**はレコードのセットを表します。最も重要なメソッドは、``count``、``select``、``update``、``delete``です。例:
``
myset = db(myquery)
rows = myset.select()
myset.update(myfield='somevalue')
myset.delete()
``:code

``Expression``:inxx
**Expression**は``orderby``や``groupby``式のようなものです。Fieldクラスは、Expressionから派生しています。下に例を示します。
``
myorder = db.mytable.myfield.upper() | db.mytable.id
db().select(db.table.ALL, orderby=myorder)
``:code

### 接続文字列
``connection strings``:inxx

データベースとの接続は、DALのオブジェクトのインスタンスを作成することによって確立されます：
``
>>> db = DAL('sqlite://storage.db', pool_size=0)
``:code

``db``はキーワードではありません。つまり、それはローカルな変数で、接続オブジェクト``DAL``を格納します。違う名前を付けても問題ありません。``DAL``のコンストラクタは1つの引数、すなわち接続文字列を必要とします。接続文字列は、特定のバックエンドのデータベースに依存する唯一のweb2pyコードです。ここでは、サポートされているバックエンドのデータベースの特定のタイプに対する接続文字列の例を示します(すべてのケースで、データベースは、デフォルトのポートでtestという名前で、localhostから動作していることを想定しています)：

-------------
**SQLite**     | ``sqlite://storage.db``
**MySQL**      | ``mysql://username:password@localhost/test``
**PostgreSQL** | ``postgres://username:password@localhost/test``
**MSSQL**      | ``mssql://username:password@localhost/test``
**FireBird**   | ``firebird://username:password@localhost/test``
**Oracle**     | ``oracle://username:password@test``
**DB2**        | ``db2://username:password@test``
**Ingres**     | ``ingres://username:password@localhost/test``
**Informix**   | ``informix://username:password@test``
**Google App Engine** | ``gae``
-------------

SQLiteではデータベースが単一のファイルからなることに注意してください。ファイルが存在しない場合には、作成されます。このファイルはアクセスするたびにロックされます。MySQL、PostgreSQL、MSSQL。FireBird、Oracle、DB2、Ingres、Informixの場合、"test"データベースはweb2pyの外で作成される必要があります。接続が確立されると、web2pyは、テーブルを適切に作成、変更、削除します。

接続文字列を``None``に設定することも可能です。この場合、DALはいかなるバックエンド・データベースにも接続しませんが、テスト用途としてAPIにはアクセス可能です。この例は、第7章で説明します。

#### 接続プール
``connection pooling``:inxx

DALのコンストラクタの2番目の引数は``pool_size``です。デフォルトでは0になります。

各リクエストに対して新規のデータベース接続を確立するのはそれなりに遅いので、web2pyは接続プール機構を実装しています。接続が確立されて、ページが処理され、トランザクションが完了すると、その接続は閉じられず、プールにされます。次のHTTPリクエストが来ると、web2pyはそのプールから接続を取得して、新規のトランザクションに利用しようと試みます。もしプールに利用可能な接続がないと、新しい接続が確立されます。

``pool_size``パラメタは、SQLiteとGAEでは無視されます。

プール内の接続は、スレッド間で順番に共有されます。つまり、それらは2つの異なるスレッドによって利用されますが、同時には利用されません。各web2pyのプロセスには1つのプールしかありません。

web2pyを起動した時は、プールは常に空です。プールは、``pool_size``の値か最大同時リクエスト数のどちらか少ない方まで成長します。つまり、``pool_size=10``でも、同時リクエスト数が5より多くなることはない場合、実際のプールサイズは5までしか成長しません。``pool_size=0``の場合は、接続プールは使用されません。

接続プールはSQLiteの場合は無視されます。特に恩恵がないからです。

#### 接続の失敗

web2pyがデータベースへの接続に失敗した場合、失敗を宣言する前に、1秒間待って、再び試みることを5回行います。接続プールの場合、プールされた接続のなかで、開いたままになっているが、しばらく利用されていないものは、データベース端末によって閉じることが可能です。再試行の機能のおかげで、web2pyは、それら切断された接続に対して再度、接続の確立を試みます。

#### 複製されたデータベース

``DAL(...)``の最初の引数には、URIのリストをとることもできます。この場合、web2pyはそれらのそれぞれに接続しようと試みます。その主な目的は、複数のデータベースサーバーに対応し、それらの間で負荷を分散させることです。ここでは典型的なユースケースを示します：

``
db = DAL(['mysql://...1','mysql://...2','mysql://...3'])
``:code

この場合、DALは最初のものに接続しようと試み、失敗したら、第2、第3のものに試みます。これは、マスタ-スレーブ構成のデータベースにおいて負荷を分散するためにも利用できます。詳細は、第11章においてスケーラビリティの文脈で説明します。

### 予約されたキーワード
``reserved Keywords``:inxx

DALのコンストラクタに渡すことのできるもう1つの引数があります。これにより、対象となるバックエンドのデータベースにおける予約されたSQLのキーワードに対してテーブルの名前や、カラムの名前をチェックすることができます。

その引数は、``check_reserved``です。これはデフォルトはNoneです。

これは、データベース・バックエンドのアダプタの名前を含む文字列のリストです。

アダプタの名前は、DALの接続文字列において使用されているものと同じです。たとえば、PostgreSQLとMSSQLに対してチェックしたい場合は、次のような接続文字列になります：
``
db = DAL('sqlite://storage.db',
         check_reserved=['postgres', 'mssql'])
``:code

DALは、リストと同じ順番で、キーワードを走査します。

"all"と"common"という2つの追加オプションがあります。allを指定すると、すべての知られているSQLキーワードに対してチェックされます。commonを指定すると、``SELECT``、``INSERT``、``UPDATE``などの一般的なSQLのキーワードだけがチェックされます。

サポートされるバックエンドに対して、非予約語のSQLキーワードに対してチェックするかどうかを指定することも可能です。この場合、``_nonreserved``をその名前の前に付けてください。例:
``
check_reserved=['postgres', 'postgres_nonreserved']
``:code

以下のデータベース・バックエンドは、予約語のチェックをサポートしています。

-----
**PostgreSQL** | ``postgres(_nonreserved)``
**MySQL** | ``mysql``
**FireBird** | ``firebird(_nonreserved)``
**MSSQL** | ``mssql``
**Oracle** | ``oracle``
-----

### ``DAL``, ``Table``, ``Field``

DALのAPIを理解する最良の方法は、それぞれの関数を自分で試してみることです。これは、web2pyのシェルを介してインタラクティブに行うことができます。ただし、最終的には、DALコードはモデルとコントローラに行きます。

接続を作成してスタートしましょう。例なので、SQLiteを使用してもよいでしょう。この議論において、バックエンドのエンジンを変更しても何も変更することはありません。

``DAL``:inxx ``SQLite``:inxx ``MySQL``:inxx ``PostgresSQL``:inxx ``Oracle``:inxx ``MSSQL``:inxx ``FireBird``:inxx ``DB2``:inxx ``Informix``:inxx
``
>>> db = DAL('sqlite://storage.db')
``:code

データベースはこれにより接続し、その接続はグローバル変数``db``に格納されます。

いつでも、接続文字列を取り出すことができます。
``_uri``:inxx
``
>>> print db._uri
sqlite://storage.db
``:code

データベースの名前も取り出せます。
``_dbname``:inxx
``
>>> print db._dbname
sqlite
``:code

接続文字列は``_uri``と呼ばれます。Uniform Resource Identifierのインスタンスだからです。

DALでは、同じデータベースや異なるデータベース、さらに、異なる種類のデータベースに対する複数の接続が可能です。ここでは、最も一般的な状況として、単一のデータベースを想定します。

``define_table``:inxx ``Field``:inxx
``type``:inxx ``length``:inxx ``default``:inxx ``requires``:inxx ``required``:inxx ``unique``:inxx
``notnull``:inxx ``ondelete``:inxx ``uploadfield``:inxx ``uploadseparate``:inxx ``migrate``:inxx ``sql.log``:inxx

DALの最も重要なメソッドは``define_table``です：
``
>>> db.define_table('person', Field('name'))
``:code

これは、"name"フィールド(カラム)を持つ"person"という``Table``オブジェクトを定義し、格納し、返しています。このオブジェクトはまた、``db.person``に関連付けられているので、その戻り値を捉える必要はありません。

### レコードの表現

これは省略可能ですが、レコードの書式表現を指定するのに推奨されます：
``
>>> db.define_table('person', Field('name'), format='%(name)s')
``:code

または
``
>>> db.define_table('person', Field('name'), format='%(name)s %(id)s')
``:code

より複雑なものは関数を用いて次のように書きます：
``
>>> db.define_table('person', Field('name'),
       format=lambda r: r.name or 'anonymous')
``:code

format属性は、2つの目的のために使用されます：
- セレクト/オプションのドロップダウンにおいて、参照先のレコードを表現するためです。
- このテーブルを参照するすべてのフィールドに対して、``db.othertable.person.represent``属性を設定するためです。これは、SQLTABLEがidによって参照を表示するのではなく、代わりに好ましい書式表現を用いることを意味します。

``Field constructor``:inxx
以下に示すのはFieldコンストラクタのデフォルトの値です：
``
Field(name, 'string', length=None, default=None,
      required=False, requires='<default>',
      ondelete='CASCADE', notnull=False, unique=False,
      uploadfield=True, widget=None, label=None, comment=None,
      writable=True, readable=True, update=None, authorize=None,
      autodelete=False, represent=None, compute=None, 
      uploadfolder=os.path.join(request.folder,'uploads'),
      uploadseparate=None)
``:code

すべてのものが各フィールドに関連しているというわけではありません。"length"は、"string"型のフィールドに対してのみ関連しています。"uploadfield"と"authorize"は、"upload"型のフィールドに対してのみ関連しています。"ondelete" は"reference"と"upload"型のフィールドに対してにみ関連しています。
- ``length``は"string"や、"password"、"upload"フィールドの最大長を設定します。``length``が指定されていない場合は、デフォルト値が使用されます。ただし、デフォルト値に関しては後方互換は保証されていません。意図しないマイグレーションやアップグレードを避けるため、string、password、uploadフィールドに対して、常にlengthを指定することを推奨します。
- ``default``はフィールドのデフォルト値を設定します。デフォルト値は値が明示的に指定されていない場合において挿入を実行したときに使用されます。また、SQLFORMを用いたテーブルによって構築されたフォームを前もって入力するために使用されます。
- ``required``はDALに、このフィールドの値が明示的に指定されていない場合、挿入することを許さないようにします。
- ``requires``はバリデータ、または、バリデータのリストです。これは、DALによっては使用されず、SQLFORMによって使用されます。以下に、与えられた型に対するデフォルトのバリデータの一覧を示します：

----------
**field type** | **default field validators**
``stringt`` | ``IS_LENGTH(length) default length is 512``
``textt`` | ``IS_LENGTH(65536)``
``blobt`` | ``None``
``booleant`` | ``None``
``integert`` | ``IS_INT_IN_RANGE(-1e100, 1e100)``
``doublet`` | ``IS_FLOAT_IN_RANGE(-1e100, 1e100)``
``decimal(n,m)t`` | ``IS_DECIMAL_IN_RANGE(-1e100, 1e100)``
``datet`` | ``IS_DATE()``
``timet`` | ``IS_TIME()``
``datetimet`` | ``IS_DATETIME()``
``passwordt`` | ``None``
``uploadt`` | ``None``
``reference <table>t`` | ``IS_IN_DB(db,'<table>.id')``
``list:stringt`` | ``None``
``list:integert`` | ``None``
``list:reference <table>t`` | ``IS_IN_DB(db,'<table>.id',multiple=True)``
----------

Decimalは、Pythonの``decimal``モジュールに定義されているような、``Decimal``オブジェクトを要求し、返します。SQLiteでは``decimal``型は処理されないので、``double``として扱われます。(n、m)はそれぞれ、合計の桁数と小数点以下の桁数です。

``list:`` フィールドは特殊です。なぜなら、NoSQL上の特定の非正規化の特徴(Google App Engineでは、``ListProperty``や``StringListProperty``といったフィールド型)に対して有利になるように、そして、それらを 他のサポートされたリレーショナル・データベースに移植できるように設計されているからです。リレーショナルデータベースでは、そのリストは``text``フィールドとして保存されます。項目は、``|``によって区切られ、文字列項目の各``|``は``||``にエスケープされます。詳細は、それ自体を扱う節において説明されています。

-------
``requires=...``は、フォーム・レベルで強制され、``required=True``はDAL(挿入)レベルで強制されることに注意してください。一方、``notnull``や``unique``、``ondelete``はデータベース・レベルで強制されます。それらは時として冗長に見えるかもしれませんが、DALを用いたプログラミングにおいて、その区別を維持することは重要です。
-------

- ``ondelete`` は"ON DELETE"SQL文へと変換されます。デフォルトでは、"CASCADE"に設定されています。これは、レコードを削除するときに、それを参照しているすべてのレコードを削除するようにデータベースに指示します。この機能を無効にするには、ondeleteを"NO ACTION"に設定してください。
- ``notnull=True`` は"NOT NULL"SQL文へと変換されます。これにより、データベースから、このフィールドにnull値が挿入されることを防ぎます。
- ``unique=True`` は"UNIQUE"SQL文へと変換され、フィールドの値が、そのテーブル内でユニークであることを保証します。これはデータベース・レベルで強制されます。
- ``uploadfield`` は"upload"型のフィールドに対してのみ適用されます。"upload"型のフィールドはどこかに保存されたファイル、デフォルトではアプリケーションの"uploads/"フォルダ以下のファイルシステム上に保存されたファイルの名前を格納します。``uploadfield``設定されている場合、ファイルは同じテーブルのblobフィールドに格納され、``uploadfield``の値はそのblobフィールドの名前になります。この点に関してはSQLFORMのコンテキストでより詳しく後述します。
- ``uploadfolder`` はデフォルトではアプリケーションの"uploads/"フォルダに成ります。別のパスが設定されている場合、ファイルは別のフォルダにアップロードされます。たとえば、``uploadfolder=os.path.join(request.folder,'static/temp')``とすると、ファイルは``web2py/applications/myapp/static/temp``フォルダにアップロードされます。
- ``uploadseparate`` は、Trueに設定されていると、ファイルはuploadfolderフォルダの異なるサブフォルダの下にアップロードされます。これは、非常に多くのファイルを同じフォルダ/サブフォルダに置くことを回避するために最適化されています。注意：システムの中断なしに、uploadseparateの値をTrueからFalseに変更することはできません。web2pyは分解したサブフォルダを使用するかしないかのどちらかしかとることはできません。ファイルをアップロードしてからこの挙動を変更すると、web2pyはそれらのファイルを取り出すことができなくなります。これが起こった場合は、ファイルを移動し、問題を解決することは可能ですが、ここでは説明しません。
- ``widget`` は、利用可能なウィジェット・オブジェクトの1つである必要があります。カスタム・ウィジェットや``SQLFORM.widgets.string.widget``などです。利用可能なウィジェットのリストは後述します。各フィールドの型は、デフォルトのウィジェットを持ちます。
- ``label`` は自動生成されるフォームにおいてこのフィールドにたいして使用されるラベルを保持する文字列(または文字列にシリアライズできるもの)です。
- ``comment`` は、このフィールドに関連付けられたコメントを保持し、自動生成されるフォームにおいて入力フィールドの右側に表示される文字列(または文字列にシリアライズできるもの)です。
- ``writable`` もしフィールドがwritableだと、自動生成される作成と更新フォームにおいて編集可能になります。
- ``readable`` もしフィールドがreadableだと、読み取り専用フォームにおいて表示されます。もしフィールドがreadableでもwritableでもない場合、作成と更新フォームにおいてフィールドは表示されません。
- ``update`` は、レコードが更新された時における、このフィールドに対するデフォルト値になります。
- ``compute`` は、オプション的な関数です。レコードが挿入、または、更新されたとき、compute関数が実行され、フィールドにはその関数の戻り値が入力されます。レコードはcompute関数にdictとして渡されます。そのdictには、そのフィールドの現在の値や、他のどのcomputeフィールドの値も含まれていません。
- ``authorize`` は、"upload"フィールドのみにおいて、対応するフィールドのアクセスコントロールに必要です。詳細は、認証と承認の文脈において後述します。
- ``autodelete`` は、アップロードされたファイルを参照するレコードが削除されたときに、対応するファイルが削除されるかどうかを決めます。"upload"フィールドに対してのみです。
- ``represent`` は、None、または、フィールド値を受け取りそのフィールド値に対する別の表現を返す関数への参照をとります。例:
``
db.mytable.name.represent = lambda name: name.capitalize()
db.mytable.other_id.represent = lambda id: db.other(id).myfield
db.mytable.some_uploadfield.represent = lambda value: \
    A('get it', _href=URL('download', args=value))
``:code

``blob``:inxx
"blob"フィールドもまた特別です。デフォルトでは、バイナリデータは、実際のデータベースフィールドに保存される前に、base64でエンコードされ、抽出時にデコードされます。これには、blobフィールドに必要なものより25%余分に記憶領域を使用するというマイナスの効果がありますが、2つの利点があります。平均的には、web2pyとデータベースサーバー間のデータ通信量を削減します。そして、通信をバックエンド固有のエスケープ規則から独立させます。

既存のテーブルに関してデータベースに問い合わせることができます：
``
>>> print db.tables
['person']
``:code

既存のフィールドに関してもテーブルに問い合わせることができます：

``fields``:inxx
``
>>> print db.person.fields
['id', 'name']
``:code

"id"というフィールドは宣言しないでください。web2pyは、何かしらの方法で、それを作成するからです。すべてのテーブルは、"id"というフィールドをデフォルトで持っています。これは、(1から始まる)自動インクリメントした整数のフィールドで、相互参照や、各レコードをユニークにするために用いられます。すなわち、"id"はプライマリーキーです。(注：idが1から始まるかはバックエンドによります。たとえばこれは、Google App Engine(GAE)では適用されません。)

``named id field``:inxx
オプション的に、``type='id'``とするフィールドを定義することができます。web2pyはこのフィールドを自動インクリメントしたidフィールドとして使用します。これは、レガシーなデータベーステーブルにアクセスするとき以外には推奨されません。いくつかの制約がありますが、複数の異なるプライマリキーを使用することもできます。これについては、"レガシー・データベースとキー付きテーブル"の節で後述します。

テーブルの型を問い合わせることができます：

``Table``:inxx
``
>>> print type(db.person)
<class 'gluon.sql.Table'>
``:code

また、DAL接続から、次のようにして、そのテーブルにアクセスすることができます：
``
>>> print type(db['person'])
<class 'gluon.sql.Table'>
``:code

同様に、フィールドの名前から、複数の同等な方法でフィールドにアクセスすることができます：
``
>>> print type(db.person.name)
<class 'gluon.sql.Field'>
>>> print type(db.person['name'])
<class 'gluon.sql.Field'>
>>> print type(db['person']['name'])
<class 'gluon.sql.Field'>
``:code

フィールドが与えられたら、その定義に設定されている属性にアクセスすることができます：
``
>>> print db.person.name.type
string
>>> print db.person.name.unique
False
>>> print db.person.name.notnull
False
>>> print db.person.name.length
32
``:code

親のテーブルやテーブル名、親の接続にもアクセスできます：
``
>>> db.person.name._table == db.person
True
>>> db.person.name._tablename == 'person'
True
>>> db.person.name._db == db
True
``:code

### マイグレーション
``migrations``:inxx

``define_table``は、対応するテーブルが存在するかどうかをチェックします。存在しない場合は、それを作成するSQLを生成し、そのSQLを実行します。テーブルが存在してもここで定義されているものと違うものであれば、そのテーブルを変更するSQLを生成し、実行します。フィー ルドの型は変更したが名前は変更してない場合、データを変更しようと試みます(そうしたくない場合は、テーブルを二度、定義し直す必要があります。一度目 はフィールドを除くことによって、そのフィールドを削除するようにweb2pyに指示します。二度目は、新規に定義したフィールドを加えて、web2py にそれを作らせます)。テーブルが存在して、現在の定義と一致する場合は、そのままになります。すべての場合において、そのテーブルを表現する``db.person``オブジェクトが作られます。

このような挙動を、ここでは"マイグレーション"として参照します。web2pyはすべてのマイグレーションとマイグレーションの試みを"databases/sql.log"ファイルにログとして記録します。

``define_table``の最初の引数は常にテーブルの名前です。他の無名引数はフィールド(Field)です。この関数はまた、"migrate"という省略可能な最後の引数をとることができます。これは、次のように名前によって明示的に参照されなければなりません：
``
>>> db.define_table('person', Field('name'), migrate='person.table')
``:code

migrateの値は、(アプリケーションの"database"フォルダ内の)ファイル名です。このファイルには、このテーブルの内部的なマイグレーション情報がweb2pyによって保存されています。これらのファイルはとても重要で、データベース全体を削除するとき以外には、削除すべきではありません。この場合は、".table"ファイルは手動で削除する必要があります。デフォルトでは、migrateはTrueに設定されています。こうすると、web2pyは接続文字列のハッシュからファイル名を生成します。migrateがFalseに設定されていると、マイグレーションは実行されません。web2pyは、データベースにテーブルが存在し、``define_table``に列挙されたフィールドを含んでいると想定します。ベストプラクティスは、明示的な名前をこのmigrateテーブルに与えることです。

同じアプリケーションに、同じmigrateファイルを持つ2つのテーブルが存在することはありません。

DALクラスはまた、"migrate"引数をとります。これは、``define_table``が呼び出されたときのmigrateのデフォルト値を設定します。例 :
``
>>> db = DAL('sqlite://storage.db', migrate=False)
``:code

このようにすると、``db.define_table``がmigrate引数なしに呼び出されたときは常に、migrateのデフォルト値がFalseに設定されます。

### 壊れたマイグレーションの修復
``fake_migrate``:inxx

マイグレーションには2つの一般的な問題があり、それらを修復する方法があります。

1つの問題は、SQLite固有のものです。SQLiteは、カラムの型を強制せず、また、カラムを削除することができません。したがって、文字列型のカラムを持っていて、それを削除した場合、それは実際には削除されません。異 なる型のカラムを再び加えようとした場合(たとえばdatetime)、(実践的にはごみとなる)文字列が含まれるデータベース・カラムを作ってしまうこ とになります。web2pyはこれに対してエラーを出しません。なぜなら、レコードを取り出して失敗するまでは、データベースに何が入っているか知らない からです。

もしweb2pyが、レコード選択時にgluon.sql.parse関数においてエラーを返す場合、これは、上記の問題によるカラム内の壊れたデータ、に関する問題になります。

解決方法は、テーブルのすべてのレコードを更新し、問題となっているカラムの値をNoneに更新することです。

もう1つの問題は、より汎用的ですが、よくMySQLにおいて見られるものです。MySQLは、トランザクション中に複数のALTER TABLEを許可しません。これは、web2pyが、複雑なトランザクションを小さなもの(一度に1つのALTER TABLE)に分解しなければならず、一つ一つコミットしなければならないことを意味します。したがって、複雑なトランザクションの一部がコミットされ、別の部分が失敗して、web2pyを壊れた状態にしてしまう可能性があります。なぜトランザクションの一部が失敗するでしょうか？なぜなら、たとえば、テーブルを変更し、文字列カラムを日付カラムに変更しようとしたとき、web2pyがそれらのデータを変換しようとするが、そのデータが変換することができない場合があるからです。web2pyはどうなるのでしょうか？テーブル構造がデータベースに実際に保存したものは正確に何なのか、ということについて混乱してしまいます。

解決策は、すべてのテーブルに対するmigrationを無効にし、次のように、fake migrationを有効にすることです：
``
db.define_table(....,migrate=True,fake_migrate=True)
``:code

これにより、テーブルに関するweb2pyのメタデータは、テーブル定義に従って再構築されます。複数のテーブル定義を行い、(マイグレーションが失敗する前のものと後のものの)どれが機能するか試してみてください。一旦成功した後は、``fake_migrate=True``属性を削除してください。

マイグレーション問題を修復しようとする前に、"applications/yourapp/databases/*.table"ファイルのコピーをとっておくのが賢明です。

### ``挿入``

テーブルが与えられると、レコードを挿入することができます
``
>>> db.person.insert(name="Alex")
1
>>> db.person.insert(name="Bob")
2
``:code

挿入によって、各挿入したレコードのユニークな"id"値が返されます。

テーブルを切捨てることができます。つまり、すべてのレコードを削除し、idのカウンタを元に戻します。 

``truncate``:inxx
``
>>> db.person.truncate()
``:code

このとき、もう一度レコードを挿入した場合、カウンタは1から始まります(これはバックエンド固有で、GAEには適用されません)：
``
>>> db.person.insert(name="Alex")
1
``:code

``bulk_insert``:inxx
web2pyはまたbulk_insertメソッドを用意しています。
``
>>> db.person.bulk_insert([{'name':'Alex'}, {'name':'John'}, {'name':'Tim'}])
[3,4,5]
``:code

これは、挿入されるフィールドの辞書のリストを受け取り、複数の挿入を一度に実行します。そして挿入された複数のレコードのIDを返します。サポートされているリレーショナルデータベースでは、この関数を使用しても、ループさせて個別に挿入を実行する場合に比べて、特に利点はありません。しかし、Google App Engineでは、大幅な高速化が見込めます。

### ``コミット``と``ロールバック``

いかなる作成、削除、挿入、切捨て、削除、更新操作も、コミットコマンドが発行されるまでは、実際にはコミットされません。

``commit``:inxx
``
>>> db.commit()
``:code

確認のため、新規のレコードを挿入してみましょう：
``
>>> db.person.insert(name="Bob")
2
``:code

そしてロールバックします。つまり、最後にコミットした時点からのすべての操作を無効にします：

``rollback``:inxx
``
>>> db.rollback()
``:code

再び挿入すると、前回の挿入はロールバックされたので、カウンタは再び2に設定されます。
``
>>> db.person.insert(name="Bob")
2
``:code

モデル、ビュー、コントローラ内のコードは、web2pyのコードにおいて次のように囲まれます：
``
try:
     execute models, controller function and view
except:
     rollback all connections
     log the traceback
     send a ticket to the visitor
else:
     commit all connections
     save cookies, sessions and return the page
``:code

web2pyにおいて``コミット``や``ロールバック``を明示的に呼び出す必要は、より細かい制御を望まない限りありません。

### 生のSQL

#### ``executesql``

DALは、SQL文を明示的に発行することを可能にします。

``executesql``:inxx
``
>>> print db.executesql('SELECT * FROM person;')
[(1, u'Massimo'), (2, u'Massimo')]
``:code

この場合、戻り値は、DALによって構文解析や変換されることはなく、その形式は特定のデータベース・ドライバに依存します。選 択において、このような利用は必要ありませんが、インデックスにおいてより一般的です。``executesql``は2つのオプション引数をとりま す：``placeholders``と``as_dict``です。``placeholders``は、SQLにおいて置換されるオプション的な値の配列、もしくは、DBドラ イバによってサポートされいれば、SQLにおいて名前付きのプレースホルダーにマッチするキーを持つ辞書です。

``as_dict``がTrueに設定されていると、DBドライバによって返される結果のカーソルは、dbフィールド名をキーとして持つ辞書の配列に変換されます。``as_dict = True``として返された結果は、通常の選択時に**.as_list()**を適用したときに返されるものと同様のものになります。
``
[{field1: value1, field2: value2}, {field1: value1b, field2: value2b}]
``:code

#### ``_lastsql``

SQLがexecutesqlを用いて手動で実行されたものなのか、DALによって生成されたSQLなのかにしても、``db._lastsql``においてSQLのコードを常に見ることができます。これは、デバッグに便利です：

``_lastdb``:inxx
``
>>> rows = db().select(db.person.ALL)
>>> print db._lastsql
SELECT person.id, person.name FROM person;
``:code

-------
web2pyは"*"演算子を利用したクエリを生成することはありません。web2pyでは常に、フィールドを選択するときは明示的です。
-------

### ``ドロップ``

最後に、テーブルを削除することができ、すべてのデータは失われます：

``drop``:inxx
``
>>> db.person.drop()
``:code

### インデックス

現在、DALのAPIはテーブルにインデックスを作成するコマンドを提供していませんが、これは**executesql**コマンドによって行うことができます。その理由は、既存のインデックスではマイグレーションが複雑になり、それを明示的に扱ったほうが良いからです。インデックスは、クエリで頻繁に使用されているフィールドに対して必要になります。

次に示すのは、SQLiteにおいてSQLを使用してインデックスを作成する例です：
``
>>> db = DAL('sqlite://storage.db')
>>> db.define_table('person', Field('name'))
>>> db.executesql('CREATE INDEX IF NOT EXISTS myidx ON person (name);')
``:code

他のデータベースの方言は非常に良く似た構文を持っていますが、オプション的な"IF NOT EXISTS"宣言をサポートしていないことがあります。

### レガシー・データベースとキー付きテーブル

web2pyは、いくつかの条件の下で、レガシー・データベースに接続することができます。

最も簡単な方法は、以下の条件を満たしているときです：
- 各テーブルは、必ず"id"と呼ばれる一意で自動インクリメントした整数フィールドを持つ
- レコードは、必ず"id"フィールドを用いてのみ参照される

-------
既存のテーブルにアクセスするとき、つまり、テーブルが現在のアプリケーションのweb2pyによって作成されていない場合、常に``migrate=False``としてください。
-------

レ ガシー・テーブルが自動インクリメントした整数フィールドを持つが、それが"id"と呼ばれていない場合、web2pyはまだそれにアクセス可能です。し かしこの場合、テーブル定義にて、``Field('....','id')``として明示的に含めなければなりません。ここで...は、自動インクリメントした 整数フィールドの名前です。

最後に、レガシー・テーブルが自動インクリメントidでないプライマリキーを使用していた場合、次の例のように、キー付きテーブルを用いてそれにアクセスすることが可能です：
``
db.define_table('account',
    Field('accnum','integer'),
    Field('acctype'),
    Field('accdesc'),
    primarykey=['accnum','acctype'],
    migrate=False)
``:code

ただし、現在、これはDB2とMS-SQL、Ingres、Informixに対してのみ利用可能です。しかし、他のものも簡単に加えることができます。

この例では、``primarykey``属性はプライマリキーからなるフィールドのリストです。書き込み時に、primarykey属性が、すべてのレガシー・テーブルと、サポートされたデータベース・バックエンドに対して機能することは保障されていません。簡単にするために、可能なら、自動インクリメントしたidフィールドを持つデータベースのビューを作成することをお勧めします。

### 分散トランザクション
``distributed transactions``:inxx

------
執筆時点では、この機能はPostgreSQL、MySQL、Firebirdに対してのみサポートされています。これらは2相コミットのAPIを公開しているためです。
------

個別のPostgreSQLデータベースに接続する2つ(またはそれ以上)の接続を持っていると仮定します：
``
db_a = DAL('postgres://...')
db_b = DAL('postgres://...')
``:code

モデルやコントローラにおいて、それらを同時にコミットすることが可能です：
``
DAL.distributed_transaction_commit(db_a, db_b)
``:code

失敗した場合は、この関数はロールバックして、``Exception``を発生させます。

コントローラにおいて、1つのアクションが返されると、もし2つの別個の接続を持ち、かつ、上記の関数を呼び出していない場合は、web2pyはそれらを個別にコミットします。これは、1つのコミットが成功し、もう一つが失敗するという可能性があることを意味します。分散トランザクションはこのようなことが起こるのを防ぎます。

### 手動アップロード

次のモデルを考えてください：
``
db.define_table('myfile',Field('image','upload'))
``:code

通常、挿入は、SQLFORMやcrudフォーム(SQLFORMの1つ)を介して自動的に処理されます。しかし、場合によっては、ファイルシステム上にすでにファイルがあり、プログラムでアップロードしたいことがあります。これは、次のような方法で行うことができます：
``
stream = open(filename,'rb')
db.myfile.insert(image=db.myfile.image.store(stream,filename))
``:code

uploadフィールドオブジェクトの``store``メソッドは、ファイルストリームとファイル名を受け取ります。ファ イル名はファイルの拡張子(型)を決めるのに使用され、(web2pyのアップロード機構に従って)そのファイルのための新しい仮の名前が作成さ れ、(特に指定がなければuploadsフォルダの下の)その新しい仮のファイルにファイルの内容がロードされます。そして、新しい仮のファイル名が返され、``db.myfile``テーブルの``image``フィールドに保存されます。

### ``Query``, ``Set``, ``Rows``

再び、以前定義した(削除した)テーブルを考え、3つのレコードを挿入します：
``
>>> db.define_table('person', Field('name'))
>>> db.person.insert(name="Alex")
1
>>> db.person.insert(name="Bob")
2
>>> db.person.insert(name="Carl")
3
``:code

テーブルは変数に格納することができます。たとえば、``person``変数として利用することができます：

``Table``:inxx
``
>>> person = db.person
``:code

フィールドも、``name``のように変数に格納することができたとえば次のようにすることができます：

``Field``:inxx
``
>>> name = person.name
``:code

クエリを(==, !=, <, >, <=, >=, like, belongsのような演算子を用いて)構築し、そのクエリを次のように変数``q``に格納することもできます：

``Query``:inxx
``
>>> q = name=='Alex'
``:code

``db``をクエリとともに呼び出すと、レコードセットを定義していることになります。次のように書いて、それを変数``s``に格納することができます：

``Set``:inxx
``
>>> s = db(q)
``:code

ここまでデータベースクエリが実行されていないことに注意してください。 DAL+クエリは、単に、このdbにおいてクエリにマッチするレコードセットを定義するだけです。web2pyはクエリからどの(複数の)テーブルが参加しているかを決めるので、実際、それを指定する必要はありません。

### ``select``

Set、``s``が与えられると、``select``コマンドを用いてレコードを取得することができます：

``Rows``:inxx ``select``:inxx
``
>>> rows = s.select()
``:code

``Row``:inxx
これは、Rowオブジェクトを要素とする``gluon.sql.Rows``クラスの反復可能なオブジェクトを返します。``gluon.sql.Row``オブジェクトは辞書のように振舞いますが、``gluon.storage.Storage``と同様、その要素は属性に関連付けられています。前者は、その値が読み取り専用であるということで後者とは異なります。

Rowsオブジェクトは、選択の結果に対しループを回して、各行の選択したフィールドをプリントできるようにすることができます：
``
>>> for row in rows:
        print row.id, row.name
1 Alex
``:code

上の一連の手順は、次のように1つの文で行うことができます：
``
>>> for row in db(db.person.name=='Alex').select():
        print row.name
Alex
``:code

``ALL``:inxx

selectコマンドは引数をとることが可能です。すべての無名引数は、取得したいフィールド名として解釈されます。たとえば、"id"と"name"フィールドを明示的に取得することができます：
``
>>> for row in db().select(db.person.id, db.person.name):
        print row.name
Alex
Bob
Carl
``:code

テーブルのALL属性によって、すべてのフィールドを指定することができます：
``
>>> for row in db().select(db.person.ALL):
        print row.name
Alex
Bob
Carl
``:code

dbにはクエリ文字列が何も渡されていないことに注目してください。web2pyは、personテーブルのすべてのフィールドが追加情報なしに要求された場合、personテーブルのすべてのレコードが要求されていることを理解します。

同等の代替構文は以下の通りです：
``
>>> for row in db(db.person.id > 0).select():
        print row.name
Alex
Bob
Carl
``:code

person(id>0)テーブルのすべてのレコードが追加情報なしに要求された場合、web2pyはpersonテーブルのすべてのフィールドが要求されていることを理解します。

#### ショートカット
``DAL shortcuts``:inxx

DALはコードを簡素化するさまざまなショートカットをサポートしています。具体例を示します：
``
myrecord = db.mytable[id]
``:code

これは、与えられた``id``を持つレコードを、それが存在すれば返します。その``id``が存在しない場合は、``None``を返します。上記の文は以下と等価です：

``
myrecord = db(db.mytable.id==id).select().first()
``:code

次のようにして、idでレコードを削除することができます：

``
del db.mytable[id]
``:code

これは以下と等価です

``
db(db.mytable.id==id).delete()
``:code

これは、与えられた``id``を持つレコードを、それが存在すれば削除します。

次のようにして、レコードを挿入することが可能です：

``
db.mytable[0] = dict(myfield='somevalue')
``:code

これは以下と等価です

``
db.mytable.insert(myfield='somevalue')
``:code

これは、右側の辞書で指定されたフィールド値を持つ新規レコードを作成します。

次のようにしてレコードを更新することができます：

``
db.mytable[id] = dict(myfield='somevalue')
``:code

これは以下と等価です

``
db(db.mytable.id==id).update(myfield='somevalue')
``:code

これは、右側の辞書で指定されたフィールド値で既存のレコードを更新します。

#### ``Row``の取り出し

さらにもう1つの便利な構文は以下の通りです：

``
record = db.mytable(id)
record = db.mytable(db.mytable.id==id)
record = db.mytable(id,myfield='somevalue')
``:code

上記の構文は、明らかに``db.mytable[id]``と似ていますが、より柔軟性が高く、安全です。まず初めに、これはidがint(または``str(id)``がint)であることを確認し、そうでない場合は``None``を返します(例外を発生させることはありません)。レコードが満たす必要のある複数の条件を指定することも可能です。条件に合わない場合は、また``None``を返します。

#### 再帰的な``select``
``recursive selects``:inxx

前述のpersonテーブルと、"person"を参照する新規の"dog"テーブルを考えます：
``
>>> db.define_table('dog', Field('name'), Field('owner',db.person))
``:code

このテーブルからの単純な選択は次のようになります：
``
>>> dogs = db(db.dog.id>0).select()
``:code

dogsの各Rowに対して、選択したテーブル(dog)からのフィールドだけでなく、リンクしたテーブルからのフィールド(再帰的に)取り出すことが可能です：
``
>>> for dog in dogs: print dog.name, dog.owner.name
``:code

ここでは、``dog.owner.name``は、dogsの各dogに対して、1回のデータベースの選択を要求するので、非効率です。利用できるときは、再帰的な選択の代わりにjoinを用いることを推奨します。とはいえ、これは個々のレコードにアクセスするときに便利で実用的です。

あるpersonによって参照されたdogsを選択して、これを逆方向で行うことも可能です：

``
person =  db.person(id)
for dog in person.dog.select(orderby=db.dog.name):
    print person.name, 'owns', dog.name
``:code

この最後の式において、``person.dog``は次のものに対するショートカットになります：
``
db(db.dog.owner==person.id)
``:code

つまり、現在の``person``によって参照された``dog``sのSetになります。この構文は、参照しているテーブルが参照されたテーブルへ複数の参照を持つ場合は、破綻します。この場合、より明示的にして、完全なクエリを使用する必要があります。


### ''ビュー''における``Rows``のシリアライズ

``SQLTABLE``:inxx
selectの結果は、次の構文を使用してビューに表示することができます：
``
{{extend 'layout.html'}}
<h1>Records</h2>
{{=db().select(db.person.ALL)}}
``:code

これは、HTMLのテーブルへと自動的に変換されます。テーブルは、ヘッダにカラム名を持ち、各行に各レコードを持っています。行は"even"と"odd"クラスで交互にマークされます。内部では、Rowsは最初にSQLTABLEオブジェクト(テーブルとは混同しないでください)へと変換され、シリアライズされます。データベースから抽出した値はまた、そのフィールドに関連付けられたバリデータによって書式化され、エスケープされます。(注：ビュー内でdbをこのような方法で用いることは、普通は、良いMVCのプラクティスとして考えられていません。)

また、SQLTABLEを明示的に呼び出すことは可能で、便利なときがあります。

SQLTABLEのコンストラクタは次のようなオプション的引数をとります：

- ``linkto`` URLまたは参照フィールドへリンクするために使用されるアクション(デフォルトはNone) 
- ``upload`` URLまたはアップロードしたファイルのダウンロードを可能にするダウンロードアクション(デフォルトはNone)
- ``headers`` フィールド名とヘッダとして用いるそのラベルをマッピングする辞書(デフォルトは``{}``)。一種の命令をすることもできます。現在は、``headers='fieldname:capitalize'``をサポートしています。
- ``truncate`` テーブル内の長い値を切り捨てるための文字数(デフォルトは16)
- ``columns`` カラムとして表示するフィールド名のリスト(tablename.fieldnameのフォーマット)。リストされていないものは表示されません(デフォルトはすべてです)。
- ``**attributes`` 最外部のTABLEオブジェクトに渡される汎用的なヘルパ属性です。

以下が具体例です：
``
{{extend 'layout.html'}}
<h1>Records</h2>
{{=SQLTABLE(db().select(db.person.ALL),
   headers='fieldname:capitalize',
   truncate=100,
   upload=URL('download'))
}}
``:code

#### ``orderby``, ``groupby``, ``limitby``, ``distinct``

``select``コマンドは5つのオプション引数をとります：orderby、groupby、limitby、left、cacheです。ここでは、最初の3つについて説明します。

次のように、nameでソートされたレコードを取り出すことができます：

``orderby``:inxx
``
>>> for row in db().select( 
        db.person.ALL, orderby=db.person.name):
        print row.name
Alex
Bob
Carl
``:code

nameの逆順でソートされたレコードを取り出すことができます(チルダに注意してください)：
``
>>> for row in db().select(  
        db.person.ALL, orderby=~db.person.name):
        print row.name
Carl
Bob
Alex
``:code

ランダムな順番で取り出したレコードを得ることが可能です：
``
>>> for row in db().select( 
        db.person.ALL, orderby='<random>'):
        print row.name
Carl
Alex
Bob
``:code

orderby='<random>'の使用はGAE上ではサポートされません。しかし、このような状況や、同様に、組み込みが十分でないような他の多くの場合は、次のように取り込むことができます：
``
import random 
rows=db(...).select().sort(lambda row: random.random())
``:code

レコードを複数のフィールドに関してソートすることができます。これはフィールドを"|"によって連結することで可能です：
``
>>> for row in db().select( 
        db.person.ALL, orderby=db.person.name|db.person.id):
        print row.name
Carl
Bob
Alex
``:code

orderbyと一緒にgroupbyを用いて、指定したフィールドの同じ値を持つレコードをグループ化することができます(これはバックエンド固有のもので、GAEでは利用できません)：
``
>>> for row in db().select( 
        db.person.ALL, 
        orderby=db.person.name, groupby=db.person.name):
        print row.name
Alex
Bob
Carl
``:code

``distinct``:inxx

``distinct=True``の引数を用いると、重複のないレコードだけを選択したい場合に指定することができます。すべての指定したフィールドを用いてグループ化するのと同じ効果を持ちます。ただしこの場合、ソートは必要ありません。distinctを用いるとき、ALLのフィールドの選択をしないことは重要です。特に、"id"フィールドの選択をしないでください。この場合、すべてのレコードが常に重複なしの状態になってしまいます。

以下に例を示します：
``
>>> for row in db().select(db.person.name, distinct=True):
        print row.name
Alex
Bob
Carl
``:code

limitbyを使用すると、レコードの一部を選択することができます(以下の例では、0から始まる最初の2つのが選択されます)：

``limitby``:inxx
``
>>> for row in db().select(db.person.ALL, limitby=(0, 2)):
        print row.name
Alex
Bob
``:code

#### 論理演算子

クエリはANDの二項演算子"&"を用いて組み合わせることができます：

``and``:inxx ``or``:inxx ``not``:inxx
``
>>> rows = db((db.person.name=='Alex') & (db.person.id>3)).select()
>>> for row in rows: print row.id, row.name
4 Alex
``:code

ORの二項演算子"|"も同様です：
``
>>> rows = db((db.person.name=='Alex') | (db.person.id>3)).select()
>>> for row in rows: print row.id, row.name
1 Alex
``:code

"!="の二項演算子によってクエリ(またはサブクエリ)を否定できます：
``
>>> rows = db((db.person.name!='Alex') | (db.person.id>3)).select()
>>> for row in rows: print row.id, row.name
2 Bob
3 Carl
``:code

または、"~"単項演算子による明示的な否定によっても可能です：
``
>>> rows = db((~db.person.name=='Alex') | (db.person.id>3)).select()
>>> for row in rows: print row.id, row.name
2 Bob
3 Carl
``:code

Pythonにおける"AND"と"OR"演算子のオーバーロードの制約により、これらはクエリの形成には使用できません。代わりに二項演算子を使用する必要があります。

#### ``count``, ``delete``, ``update``

セット内のレコードをカウントすることができます：

``count``:inxx
``
>>> print db(db.person.id > 0).count()
3
``:code

セット内のレコードを削除することができます：

``delete``:inxx
``
>>> db(db.person.id > 3).delete()
``:code

セット内のすべてのレコードを更新することができます。これは、更新が必要なフィールドに対応する名前付き引数を渡すことで可能です。

``update``:inxx
``
>>> db(db.person.id > 3).update(name='Ken')
``:code

#### 式

更新文に割り当てられる値は式でも可能です。たとえば、次のようなモデルで考えてください
``
>>> db.define_table('person',
        Field('name'),
        Field('visits', 'integer', default=0))
>>> db(db.person.name == 'Massimo').update(
        visits = db.person.visits + 1)
``:code

クエリで使用される値もまた、式にすることができます
``
>>> db.define_table('person',
        Field('name'),
        Field('visits', 'integer', default=0),
        Field('clicks', 'integer', default=0))
>>> db(db.person.visits == db.person.clicks + 1).delete()
``:code

#### ``update_record``

``update_record``:inxx
web2pyではまた、``update_record``を用いてすでにメモリにある単一のレコードを更新することが可能です。
``
>>> rows = db(db.person.id > 2).select()
>>> row = rows[0]
>>> row.update_record(name='Curt')
``:code

これは次のものと混同しないでください
``
>>> row.update(name='Curt')
``:code

その理由は、単一のrowに対して、``update``メソッドはrowオブジェクトを更新しますが、``update_record``のようにデータベースのレコードを更新することはないからです。

#### ``first`` and ``last``
``first``:inxx ``last``:inxx

レコードを保持したRowsオブジェクトが与えられたとき、次のようにすることができます：

``
>>> rows = db(query).select()
>>> first_row = rows.first()
>>> last_row = rows.last()
``:code

これは以下のものに相当します。
``
>>> first_row = rows[0] if len(rows)>0 else None
>>> last_row = rows[-1] if len(rows)>0 else None
``:code

#### ``as_dict`` and ``as_list``
``as_list``:inxx ``as_dict``:inxx

Rowオブジェクトは、``as_dict()``メソッドを用いて標準の辞書にシリアライズすることが可能です。Rowsオブジェクトは、**as_list()**メソッドを用いて辞書のリストにシリアライズすることが可能です。例をいくつか示します：
``
>>> rows = db(query).select()
>>> rows_list = rows.as_list()
>>> first_row_dict = rows.first().as_dict()
``:code

これらのメソッドは、Rowsを汎用的なビューに渡したり、Rowsをセッションに保存したりするのに便利です(Rowsオブジェクト自体は、開いているDB接続への参照があるのでシリアライズできません)：
``
>>> rows = db(query).select()
>>> session.rows = rows # not allowed!
>>> session.rows = rows.as_list() # allowed!
``:code

#### ``find``, ``exclude``, ``sort``
``find``:inxx ``exclude``:inxx ``sort``:inxx

2つの選択を行い、その1つが前回の選択のサブセットを保持しているようなことを実行したいときがよくあります。この場合、データベースに再びアクセスするのは要領を得ません。``find``、``exclude``、``sort``オブジェクトを利用すると、Rowsオブジェクトを操作し、データベースのアクセスなしにもう1つのものを生成することが可能になります。具体的には次のようになります：
- ``find`` は、条件でフィルタされた新規のRowsセットを返します。元のものはそのままです。
- ``exclude`` は、条件でフィルタされた新規のRowsセットを返します。それらは元のものから取り除かれます。
- ``sort`` は、条件でソートされた新規のRowsセットを返します。元のものはそのままです。

これらすべてのメソッドは、単一の引数として、各行に対して作用する関数をとります。

これはその使用例です：
``
>>> db.define_table('person',Field('name'))
>>> db.person.insert(name='John')
>>> db.person.insert(name='Max')
>>> db.person.insert(name='Alex')
>>> rows = db(db.person.id>0).select()
>>> for row in rows.find(lambda row: row.name[0]=='M'): 
        print row.name
Max
>>> print len(rows)
3
>>> for row in rows.exclude(lambda row: row.name[0]=='M'): 
        print row.name
Max
>>> print len(rows)
2
>>> for row in rows.sort(lambda row: row.name): 
        print row.name
Alex
John
``:code

これらは組み合わせることができます：
``
>>> rows = db(db.person.id>0).select()
>>> rows = rows.find(
        lambda row: 'x' in row.name).sort(
            lambda row: row.name)
>>> for row in rows: 
        print row.name
Alex
Max
``:code

### 計算されたフィールド
``compute``:inxx

DALのフィールドは``compute``フィールドを持つことがあります。これは、Rowオブジェクトをとり、そのフィールドに対する値を返す関数(またはラムダ)でなければなりません。新規のレコードが挿入や更新などで変更されるとき、そのフィールドに対する値が用意されていない場合、web2pyは``compute``関数を用いて他のフィールドの値から計算しようとします。以下がその例です。
``
>>> db.define_table('item',
        Field('unit_price','double'),
        Field('quantity','integer'),
        Field('total_price',
            compute=lambda r: r['unit_price']*r['quantity']))
>>> r = db.item.insert(unit_price=1.99, quantity=5)
>>> print r.total_price
9.95
``:code

なお、計算された値はdbに格納され、後述する仮想フィールドの場合のように再取得時に計算されることはありません。2つの典型的な計算されたフィールドの活用方法があります：
- wikiアプリケーションにおいて、HTMLに加工されたwikiの入力テキストを、リクエスト毎の加工を避けるために保存する
- 検索用に、フィールドの正規化した値を計算し、検索時に使用する

### 仮想フィールド
``virtualfields``:inxx

仮想フィールドもまた、(前節のように)計算されたフィールドですが、それらは異なります。なぜなら、データベースには保存されず、また、データベースからレコードが取り出されるたびに計算されるという点で仮想であるからです。追加の保存先なしに単純にユーザーコードを用いることができますが、それを用いて検索することはできません。

1つ以上の仮想フィールドを定義するためには、コンテナクラスを定義し、インスタンス化し、テーブルまたは選択に対してリンクさせる必要があります。たとえば、次のようなテーブルを考えてください：
``
>>> db.define_table('item',
        Field('unit_price','double'),
        Field('quantity','integer'),
``:code

このとき、total_priceという仮想フィールドを次のように定義できます
``
>>> class MyVirtualFields(object):
        def total_price(self):
            return self.item.unit_price*self.item.quantity
>>> db.item.virtualfields.append(MyVirtualFields())
``:code

単一の引数(self)をとるこのクラスの各メソッドが、新規の仮想フィールドになることに注意してください。フィールドの値は``self.item.unit_price``のように完全パスで参照されます。テーブルは、このクラスのインスタンスをテーブルの``virtualfields``属性に追加することによって、この仮想フィールドにリンクされます。

仮想フィールドもまた、次のように再帰的なフィールドにアクセスできます
``
>>> db.define_table('item',
        Field('unit_price','double'))
>>> db.define_table('order_item',
        Field('item',db.item),
        Field('quantity','integer'))
>>> class MyVirtualFields(object):
        def total_price(self):
            return self.order_item.item.unit_price \ 
                * self.order_item.quantity
>>> db.order_item.virtualfields.append(MyVirtualFields())
``:code

再帰的なフィールドは``self.order_item.item.unit_price``にアクセスしていますが、ここで、``self``はループで回されているレコードであることに注意してください。

これらは、結合(JOIN)の結果に対しても作用することができます
``
>>> db.define_table('item',
        Field('unit_price','double'))
>>> db.define_table('order_item',
        Field('item',db.item),
        Field('quantity','integer'))
>>> rows = db(db.order_item.item==db.item.id).select()
>>> class MyVirtualFields(object):
        def total_price(self):
            return self.item.unit_price \
                * self.order_item.quantity
>>> rows.setvirtualfields(order_item=MyVirtualFields())
>>> for row in rows: print row.order_item.total_price
``:code

この場合、どのように構文が異なっているかに注意してください。仮想フィールドは、join選択に属している``self.item.unit_price``と``self.order_item.quantity``の両方にアクセスしています。仮想フィールドは行オブジェクトの``setvirtualfields``メソッドを用いてテーブルの行に付け加えられます。このメソッドは任意の数の名前付き引数をとります。そして次のように、複数のクラスで定義された複数の仮想フィールドを設定し、それらを複数のテーブルに付け加えることができます：
``
>>> class MyVirtualFields1(object):
        def discounted_unit_price(self):
            return self.item.unit_price*0.90
>>> class MyVirtualFields2(object):
        def total_price(self):
            return self.item.unit_price \
                * self.order_item.quantity
        def discounted_total_price(self):
            return self.item.discounted_unit_price \
                * self.order_item.quantity
>>> rows.setvirtualfields(
        item=MyVirtualFields1(),
        order_item=MyVirtualFields2())
>>> for row in rows: 
        print row.order_item.discounted_total_price
``:code

仮想フィールドは遅延(lazy)することが可能です。そのためにやることは、次のように、関数を返すようにして、その関数を呼び出すことです：
``
>>> db.define_table('item',
        Field('unit_price','double'),
        Field('quantity','integer'),
>>> class MyVirtualFields(object):
        def lazy_total_price(self):
            def lazy(self=self):
                return self.item.unit_price \
                    * self.item.quantity
            return lazy
>>> db.item.virtualfields.append(MyVirtualFields())
>>> for item in db(db.item.id>0).select():
        print item.lazy_total_price()
``:code

または、ラムダ関数を用いてより短くします：
``
>>> class MyVirtualFields(object):
        def lazy_total_price(self):
            return lambda self=self: self.item.unit_price \ 
                * self.item.quantity
``:code

### 1対多のリレーション
``one to many``:inxx

web2pyのDALを用いて1対多のリレーションをどのように実装するかを説明するために、"person"テーブルを参照するもう1つの"dog"テーブルを定義します。"person"もここで再定義します：
``
>>> db.define_table('person',
                    Field('name'),
                    format='%(name)s')
>>> db.define_table('dog',
                    Field('name'),
                    Field('owner', db.person),
                    format='%(name)s')
``:code

"dog"テーブルは、dogの名前(name)とdogの飼い主(owner)という2つのフィールドを持ちます。フィールドの型が他のテーブルのとき、そのフィールドが他のテーブルをそのidによって参照することを意図しています。実際、実在の型の値を出力し、得ることができます：
``
>>> print db.dog.owner.type
reference person
``:code

ここで、2つはAlexによって所有され、1つはBobによって所有された3匹のdogsを挿入します：
``
>>> db.dog.insert(name='Skipper', owner=1)
1
>>> db.dog.insert(name='Snoopy', owner=1)
2
>>> db.dog.insert(name='Puppy', owner=2)
3
``:code

他のいかなるテーブルに対して行ったように選択することができます：
``
>>> for row in db(db.dog.owner==1).select():
        print row.name
Skipper
Snoopy
``:code

dogはpersonへの参照を持っているため、personは複数のdogsを持つことができます。したがって、personテーブルのレコードはこのとき、dogという新規の属性を獲得します。これにより、すべてのpersonsに対してループを回して、それらのdogsを取得することが簡単にできるようになります：

``referencing``:inxx
``
>>> for person in db().select(db.person.ALL):
        print person.name
        for dog in person.dog.select():
            print '    ', dog.name
Alex
     Skipper
     Snoopy
Bob
     Puppy
Carl
``:code

#### 内部結合(Inner Joins)

同様の結果を得るための別の方法は、join、具体的には、INNER JOINを用いることです。web2pyは、次の例のようにクエリが2つ以上のテーブルをリンクするときに、joinを自動的に透過的に実行します。

``Rows``:inxx ``inner join``:inxx ``join``:inxx
``
>>> rows = db(db.person.id==db.dog.owner).select()
>>> for row in rows:
        print row.person.name, 'has', row.dog.name
Alex has Skipper
Alex has Snoopy
Bob has Puppy
``:code

web2pyがjoinを行って、rowsが、一緒にリンクされた各テーブル由来の2つのレコードを含んでいることを見てください。2つのレコードは競合する名前のフィールドを持つ可能性があるので、rowからのフィールド値を取り出すときに、テーブルを指定する必要があります。つまり、次のことをする前は：
``
row.name
``:code

これがpersonの名前なのか、dogの名前なのかは明らかでした。joinの結果においては、次のようにより明示的なものにする必要があります：
``
row.person.name
``:code

または：
``
row.dog.name
``:code

#### 左外部結合(Left Outer Join)

Carlは彼が犬を持っていないので、上記のリストには現れなかったことに気づいてください。personsと(所持しているならば)彼らのdogsを(彼らがdogsを所持しているかに関係なく)選択しようとした場合、LEFT OUTER JOINを実行する必要があります。これは、selectコマンドの"left"引数を用いて行うことができます。以下がその例です：
``Rows``:inxx ``left outer join``:inxx ``outer join``:inxx
``
>>> rows=db().select(
        db.person.ALL, db.dog.ALL, 
        left=db.dog.on(db.person.id==db.dog.owner))
>>> for row in rows:
        print row.person.name, 'has', row.dog.name
Alex has Skipper
Alex has Snoopy
Bob has Puppy
Carl has None
``:code

ここで：
``
left = db.dog.on(...)
``:code

これはleft joinクエリを行います。``db.dog.on``の引数は、joinに必要な条件になります(上述のinner joinで使用したものと同じです)。left joinの場合、どのフィールドを選択するかは明示的にする必要があります。

#### グループ化とカウント

結合(join)を行うとき、特定の条件に従って行をグループ化し、カウントしたい場合があります。たとえば、各personにおいて所有するdogsの数をカウントするなどです。web2pyではこれも同様に行うことができます。初めに、カウント演算子が必要になります。第2に、personテーブルをdogテーブルを所有者(owner)によってjoinします。第3に、すべての行(person + dog)を選択し、person毎にそれらをグループ化して、グループ化している最中にカウントします：

``grouping``:inxx
``
>>> count = db.person.id.count()
>>> for row in db(db.person.id==db.dog.owner).select(
        db.person.name, count, groupby=db.person.name):
        print row.person.name, row[count]
Alex 2
Bob 1
``:code

(組み込みの)カウント演算子はフィールドとして用いられていることに注意してください。ここでの唯一の問題は、どのように情報を取り出すかにあります。各行は明らかに1人のpersonとカウントを含んでいます。しかし、カウントはpersonのフィールドではなく、テーブルでもありません。では、どこに行くのでしょうか？キーがクエリの式自体と同じであるレコードを表現するような格納オブジェクトに行きます。

### 多対多
``many-to-many``:inxx

前述の例では、1匹のdogは1人の所有者(owner)を持つけれど、1人のpersonは多くのdogsを持つようにしました。AlexとCurtによって所有されたSkipperはどうなるのでしょうか？これには多対多のリレーションが必要です。そしてこれは、所有(ownership)関係で1人のpersonと1匹のdogをリンクする中間テーブルを介して実現されます。

どのようにそれを行うかを以下に示します：
``
>>> db.define_table('person',
                    Field('name'))
>>> db.define_table('dog',
                    Field('name'))
>>> db.define_table('ownership',
                    Field('person', db.person),
                    Field('dog', db.dog))
``:code

これまでの所有(ownership)関係は次のように書き換えることができます：
``
>>> db.ownership.insert(person=1, dog=1) # Alex owns Skipper
>>> db.ownership.insert(person=1, dog=2) # Alex owns Snoopy
>>> db.ownership.insert(person=2, dog=3) # Bob owns Puppy
``:code

今度は、CurtがSkipperを共同所有するという新しいリレーションを加えることができます：
``
>>> db.ownership.insert(person=3, dog=1) # Curt owns Skipper too
``:code

3方向のテーブル間のリレーションを持っているので、操作を実行する上で、次のような新規のセットを定義するのは便利です：
``
>>> persons_and_dogs = db(
        (db.person.id==db.ownership.person) \
        & (db.dog.id==db.ownership.dog))
``:code

ここで、新規のSetからすべてのpersonsと彼らのdogsを選択するのは簡単です：
``
>>> for row in persons_and_dogs.select():
        print row.person.name, row.dog.name
Alex Skipper
Alex Snoopy
Bob Puppy
Curt Skipper
``:code

同様に、Alexが所有するすべてのdogsを検索することもできます：
``
>>> for row in persons_and_dogs(db.person.name=='Alex').select():
        print row.dog.name
Skipper
Snoopy
``:code

そして、Skipperの所有者も検索することができます：
``
>>> for row in persons_and_dogs(db.dog.name=='Skipper').select():
        print row.person.name
Alex
Curt
``:code

多対多への軽い代替案はタグ付けです。タグ付けは``IS_IN_DB``の文脈で後述します。タグ付けは、Google App EngineのようなJOINをサポートしていないデータベース・バックエンドでも機能します。

### 多対多、``list:<type>``、``contains``
``list:string``:inxx
``list:integer``:inxx
``list:reference``:inxx
``contains``:inxx
``multiple``:inxx
``tags``:inxx

web2pyは、以下の特別なフィールド型を用意しています：

``
list:string
list:integer
list:reference <table>
``:code

これらはそれぞれ、文字列、整数、参照のリストを収容します。

Google App Engineでは、``list:string``は``StringListProperty``にマッピングされ、他の2つは、``ListProperty(int)``にマッピングされます。リレーショナル・データベースでは、``|``によって区切られた項目のリストを持つテキストフィールドにマッピングされます。たとえば、``[1,2,3]``は``|1|2|3|``にマッピングされます。

文字列のリストでは、項目内の任意の``|``が``||``に置換されるように項目はエスケープされます。いずれにせよ、これは内部表現でありユーザーに対しては透過的です。

次の例のように``list:string``を用いることができます：

``
>>> db.define_table('product',
        Field('name'),
        Field('colors','list:string'))
>>> db.product.colors.requires=IS_IN_SET(('red','blue','green'))
>>> db.product.insert(name='Toy Car',colors=['red','green'])
>>> products = db(db.product.colors.contains('red')).select()
>>> for item in products: 
        print item.name, item.colors
Toy Car ['red', 'green']
``:code

``list:integer``も同様に機能します。ただし、項目は整数でなければなりません。

例のごとく、この要求は、``insert``レベルではなく、フォームレベルで強制されます。

------
``list:<type>``フィールドにおいて、``contains(value)``演算子は、``value``が含まれているかをリストに対してチェックする自明でないクエリにマッピングされます。``contains``演算子は標準の``string``と``text``フィールドでも機能し、``LIKE '%value%'``にマッピングされます。
------

``list:reference``と``contains(value)``演算子は、多対多リレーションの非正規化にとって特に有用です。以下がその例です。

``
>>> db.define_table('tag',Field('name'),format='%(name)s')
>>> db.define_table('product',
        Field('name'),
        Field('tags','list:reference tag'))
>>> a = db.tag.insert(name='red')
>>> b = db.tag.insert(name='green')
>>> c = db.tag.insert(name='blue')
>>> db.product.insert(name='Toy Car',tags=[a, b, c])
>>> products = db(db.product.tags.contains(b)).select()
>>> for item in products: 
        print item.name, item.tags
Toy Car [1, 2, 3]
>>> for item in products:
        print item.name, db.product.tags.represent(item.tags)
Toy Car red, green, blue
``:code

``list:reference``のtagフィールドは次のようなデフォルトの制約を得ることに注意してください

``
requires = IS_IN_DB(db,'tag.id',db.tag._format,multiple=True)
``:code

これは、フォームにおいて``SELECT/OPTION``の複数ドロップボックスをを生成します。

また、このフィールドはデフォルトで、書式化した参照のカンマ区切りのリストとして参照リストを表現する``represent``属性を得ることにも注意してください。これは、フォームと``SQLTABLE``の読み込み時に利用されます。

-----
``list:reference``はデフォルトのバリデータとデフォルトの表現を持つ一方、``list:integer``と``list:string``は持ちません。したがって、これら2つに関しては、フォームにおいてそれらを利用する場合、``IS_IN_SET``か``IS_IN_DB``バリデータが必要になります。
-----

### その他の演算子

web2pyには、同等なSQL演算子にアクセスするためのAPIを提供する演算子があります。"log"という別のテーブルを定義してみます。そのテーブルでは、セキュリティ・イベントとそのevent_timeと重大度(severity)を保存するようにします。ここで重大度(severity)は整数です。

``date``:inxx ``datetime``:inxx ``time``:inxx
``
>>> db.define_table('log', Field('event'),
                           Field('event_time', 'datetime'),
                           Field('severity', 'integer'))
``:code

前回と同様、イベントとして、"port scan"と "xss injection"と"unauthorized login"を数個挿入します。例として、同じevent_timeを持つが重大度(それぞれ1,2,3)は異なるイベントをログとして記録します。
``
>>> import datetime
>>> now = datetime.datetime.now()
>>> print db.log.insert(
        event='port scan', event_time=now, severity=1)
1
>>> print db.log.insert(
        event='xss injection', event_time=now, severity=2)
2
>>> print db.log.insert(
        event='unauthorized login', event_time=now, severity=3)
3
``:code

#### ``like, startswith, contains, upper, lower``
``like``:inxx ``startswith``:inxx
``contains``:inxx ``upper``:inxx ``lower``:inxx

フィールドは、文字列を照合するためのlike演算子を持っています：

``
>>> for row in db(db.log.event.like('port%')).select():
        print row.event
port scan
``:code

ここで、"port%"は"port"から始まる文字列を示しています。パーセント記号文字"%"は、"任意の文字列"を意味するワイルドカード文字です。

web2pyはまた、いくつかのショートカットを提供しています：

``
db.mytable.myfield.startswith('value')
db.mytable.myfield.contains('value')
``:code

これは、それぞれに以下に相当します

``
db.mytable.myfield.like('value%')
db.mytable.myfield.like('%value%')
``:code

``contains``は、前節で説明したように、``list:<type>``フィールドに対して特別な意味を持つことに注意してください。

同様に、フィールドの値を大文字、または、小文字に変換するために``upper``と``lower``メソッドを使用することができます。さらに、like演算子と組み合わせることができます。

``upper``:inxx ``lower``:inxx
``
>>> for row in db(db.log.event.upper().like('PORT%')).select():
        print row.event
port scan
``:code

#### ``year``, ``month``, ``day``, ``hour``, ``minutes``, ``seconds``
``hour``:inxx ``minutes``:inxx ``seconds``:inxx ``day``:inxx ``month``:inxx ``year``:inxx

dateとdatetimeフィールドはday、month、yearメソッドを持ちます。datetimeおよびtimeフィールドは、hour、minutes、secondsメソッドを持ちます。以下がその例です：

``
>>> for row in db(db.log.event_time.year()==2009).select():
        print row.event
port scan
xss injection
unauthorized login
``:code

#### ``belongs``

SQLのIN演算子はbelongsメソッドを介して実現されます。このメソッドは、フィールドの値が指定したセット(タプルのリスト)に所属しているときtrueを返します。

``belongs``:inxx
``
>>> for row in db(db.log.severity.belongs((1, 2))).select():
        print row.event
port scan
xss injection
``:code

DALはまた、belongs演算子の引数においてネストした選択をできるようにしています。唯一の注意点は、ネストした選択は``select``ではなく``_select``でなければならず、セットを定義する唯一つのフィールドが明示的に選択されなければなりません。

``nested select``:inxx
``
>>> bad_days = db(db.log.severity==3)._select(db.log.event_time)
>>> for row in db(db.log.event_time.belongs(bad_days)).select():
        print row.event
port scan
xss injection
unauthorized login
``:code

``sum``:inxx
前回は、カウント演算子をレコードのカウントに使用しました。同様に、サム(sum)演算子を、レコードのグループから特定のフィールドの値を足す(sum)ことに用いることができます。カウントの場合と同様に、サムの結果は格納オブジェクトから取り出すことができます：
``
>>> sum = db.log.severity.sum()
>>> print db().select(sum).first()[sum]
6
``:code

### 生SQLの生成
``raw SQL``:inxx

場合によっては、SQLは生成したいが実行したくないことがあります。web2pyでこれを行うのは簡単です。なぜならデータベースIOを実行するすべてのコマンドは、単純に、実行されようとしたSQLを実行せずに返す同等のコマンドを持つからです。これらのコマンドは、機能するものと同じ名前と構文を持ちますが、アンダースコアで始まります：

これは``_insert`` ``_insert``:inxxです：
``
>>> print db.person._insert(name='Alex')
INSERT INTO person(name) VALUES ('Alex');
``:code

これは``_count`` ``_count``:inxxです
``
>>> print db(db.person.name=='Alex')._count()
SELECT count(*) FROM person WHERE person.name='Alex';
``:code

これは``_select`` ``_select``:inxxです
``
>>> print db(db.person.name=='Alex')._select()
SELECT person.id, person.name FROM person WHERE person.name='Alex';
``:code

これは``_delete`` ``_delete``:inxxです
``
>>> print db(db.person.name=='Alex')._delete()
DELETE FROM person WHERE person.name='Alex';
``:code

最後に、これは``_update`` ``_update``:inxxです
``
>>> print db(db.person.name=='Alex')._update()
UPDATE person SET  WHERE person.name='Alex';
``:code

-----
さらに、``db._lastsql``を用いて、最後のSQLコードを返すことができます。これは、executesqlを用いて手動で実行されたSQLでも、DALによって生成されたSQLでも可能です。
-----

### データのエクスポートとインポート
``export``:inxx ``import``:inxx

#### CSV(一度に1つのテーブル)

DALのRowsオブジェクトが文字列に変換されるとき、自動的にCSV形式にシリアライズされます：

``csv``:inxx
``
>>> rows = db(db.person.id==db.dog.owner).select()
>>> print rows
person.id,person.name,dog.id,dog.name,dog.owner
1,Alex,1,Skipper,1
1,Alex,2,Snoopy,1
2,Bob,3,Puppy,2
``:code

単一のテーブルをCSV形式にシリアライズして、"test.csv"ファイルに保存することができます：
``
>>> open('test.csv', 'w').write(str(db(db.person.id).select()))
``:code

そして、次のようにして簡単にそれを読み取ることができます：
``
>>> db.person.import_from_csv_file(open('test.csv', 'r'))
``:code

インポートするときに、web2pyはCSVのヘッダにあるフィールド名を探します。この例では、"person.name"と"person.id"という2つのカラムを見つけます。"person"という接頭辞と、"id"というフィールドは無視されます。そして、すべてのレコードは追加され、新しいIDが割り当てられます。これら両方の操作はappadminのWeb・インターフェースを介して行うことができます。

#### CSV(すべてのテーブルを一度に)

web2pyでは、次の2つのコマンドでデータベース全体をバックアップ/復元することができます：

エクスポートするには：
``
>>> db.export_to_csv_file(open('somefile.csv', 'wb'))
``:code

インポートするには：
``
>>> db.import_from_csv_file(open('somefile.csv', 'rb'))
``:code

このメカニズムは、インポートしたデータベースがエクスポートするデータベースと異なるタイプのものでも使用することができます。データは"somefile.csv"にCSVファイルとして保存されます。このファイルでは、各テーブルは、テーブル名を示す一つの行と、フィールド名を持つもう1つの行から始まります：
``
TABLE tablename
field1, field2, field3, ...
``:code

2つのテーブルは``\r\n\r\n``で区切られます。ファイルは次の行で終わります
``
END
``:code

このファイルには、アップロードしたファイルは、それらがデータベースに保存されていない限り含まれません。どのような場合でも、"uploads"フォルダを個別に圧縮することは十分簡単です。

インポートするとき、新規のレコードは、データベースが空でない場合、データベースに追加されます。一般に、新しくインポートしたレコードは元の(保存した)レコードと同じレコードidを持つことはありません。しかし、web2pyは参照は復元するので、idの値が変化しても参照が機能しなくなることはありません。

もしテーブルに"uuid"と呼ばれるフィールドが含まれる場合、そのフィールドは重複を識別するために使用されます。またもしインポートしたレコードが既存のレコードと同じ"uuid"を持つ場合、前のレコードは更新されます。

#### CSVとリモート・データベースの同期

次のモデルを考えてください：
``
db = DAL('sqlite:memory:')
db.define_table('person',
    Field('name'),
    format='%(name)s')
db.define_table('dog',
    Field('owner', db.person),
    Field('name'),
    format='%(name)s')

if not db(db.person.id>0).count():
    id = db.person.insert(name="Massimo")
    db.dog.insert(owner=id, name="Snoopy")
``:code

各レコードは、IDによって識別され、そのIDによって参照されます。別々にインストールしたweb2pyによって利用されるデータベースの2つのコピーを持っているなら、IDは各データベースにおいてのみユニークで、データベース全体ではユニークではありません。これは、異なるデータベースからレコードをマージするときに問題になります。

データベース全体でレコードを一意に識別できるようにするには、レコードを次のようにする必要があります：
- 一意のID(UUID)を持たせる
- event_timeを持たせる(複数のコピーにてどちらがより最近のものかを判別するために)
- idの代わりにUUIDで参照する

これはweb2pyを変更することなく実現できます。以下にどのようにするかを示します：

**1.** 上記のモデルを次のように変更します：

``
db.define_table('person',
    Field('uuid', length=64, default=uuid.uuid4()),
    Field('modified_on', 'datetime', default=now),
    Field('name'),
    format='%(name)s')

db.define_table('dog',
    Field('uuid', length=64, default=uuid.uuid4()),
    Field('modified_on', 'datetime', default=now),
    Field('owner', length=64),
    Field('name'),
    format='%(name)s')

db.dog.owner.requires = IS_IN_DB(db,'person.uuid','%(name)s')

if not db(db.person.id).count():
    id = uuid.uuid4()
    db.person.insert(name="Massimo", uuid=id)
    db.dog.insert(owner=id, name="Snoopy")
``:code

**2.** データベースをエクスポートするコントローラのアクションを作成します：

``
def export():
    s = StringIO.StringIO()
    db.export_to_csv_file(s)
    response.headers['Content-Type'] = 'text/csv'
    return s.getvalue()
``:code

**3.** 他のデータベースの保存したコピーをインポートし、レコードを同期するコントローラのアクションを作成します：

``
def import_and_sync():
    form = FORM(INPUT(_type='file', _name='data'), INPUT(_type='submit'))
    if form.accepts(request.vars):
        db.import_from_csv_file(form.vars.data.file,unique=False)
        # for every table
        for table in db.tables:
            # for every uuid, delete all but the latest
            items = db(db[table].id>0).select(db[table].id,
                       db[table].uuid,
                       orderby=db[table].modified_on,
                       groupby=db[table].uuid)
            for item in items:
                db((db[table].uuid==item.uuid)&\
                   (db[table].id!=item.id)).delete()
    return dict(form=form)
``:code

**4.** uuidによる検索を高速化するためにインデックスを手動で作成します。

ただし、ステップ2と3はすべてのデータベースモデルで機能します。これらはこの例に固有のものではないからです。

別の方法として、XML-RPCを用いてファイルをエクスポート/インポートすることができます。

レコードがアップロードしたファイルを参照する場合、uploadsフォルダの中身もまたエクスポート/インポートする必要があります。ただし、そこにあるファイルはUUIDですでにラベル付けされているので、名前の衝突と参照を心配する必要はありません。

#### HTML/XMLの(一度に1つのテーブル)

DALのRowsオブジェクトはまた、(ヘルパのように)自身をXML/HTMLへとシリアライズする``xml``メソッドを持ちます：

``HTML``:inxx

``
>>> rows = db(db.person.id > 0).select()
>>> print rows.xml()
<table>
  <thead>
    <tr>
      <th>person.id</th>
      <th>person.name</th>
      <th>dog.id</th>
      <th>dog.name</th>
      <th>dog.owner</th>
    </tr>
  </thead>
  <tbody>
    <tr class="even">
      <td>1</td>
      <td>Alex</td>
      <td>1</td>
      <td>Skipper</td>
      <td>1</td>
    </tr>
    ...
  </tbody>
</table>
``:code

DALのRowsを、カスタムタグを持った他のXMLフォーマットへとシリアライズしたい場合は、普遍的なタグヘルパや*表記を使用して簡単に行うことができます：
``XML``:inxx

``
>>> rows = db(db.person.id > 0).select()
>>> print TAG.result(*[TAG.row(*[TAG.field(r[f], _name=f) \
          for f in db.person.fields]) for r in rows])
<result>
  <row>
    <field name="id">1</field>
    <field name="name">Alex</field>
  </row>
  ...
</result>
``:code

#### データ表現

**export_to_csv_file**関数はキーワード引数``represent``を受け入れます。Trueの場合、データのエクスポート中に、生のデータの代わりに、カラムの``represent``関数を用います。

この関数はまた、エクスポートしたいカラムの名前のリストを保持するキーワード引数``colnames``を受け入れます。デフォルトではすべてのカラムになります。

``export_to_csv_file``と``import_from_csv_file``の両方とも、CSVの構文解析機に保存/読み込み先のファイルのフォーマットを知らせる次のようなキーワード引数を受け入れます：
- ``delimiter``: 値を区切る区切り文字(デフォルトは',')
- ``quotechar``: 文字列の値を引用するために使用する文字(デフォルトはダブルクォート)
- ``quoting``: 引用体系(デフォルトは``csv.QUOTE_MINIMAL``)

ここではいくつか使用例を示します：
``
>>> import csv
>>> db.export_to_csv_file(open('/tmp/test.txt', 'w'),
        delimiter='|',
        quotechar='"',
        quoting=csv.QOUTE_NONNUMERIC)
        quoting=csv.QUOTE_NONNUMERIC)
``:code

Which would render something similar to
``
"hello"|35|"this is the text description"|"2009-03-03"
``:code

より詳細な情報は公式のPythonドキュメントを参照してください。``quoteall``:cite

### 選択のキャッシュ

selectメソッドはcache引数を取ります。これはデフォルトではNoneです。キャッシュの利用の際は、ここにタプルを設定する必要があります。このタプルの最初の要素はキャッシュモデルで(cache.ram、chace.diskなど)、第2の要素は秒単位の有効期限です。

次の例では、前に定義したdb.logテーブルに対する選択をキャッシュするコントローラを示しています。実際の選択では、60秒間隔より頻繁にバックエンドのデータベースからデータを取り出すことはなく、cache.ramに結果を保存します。このコントローラへの次の呼び出しが最後のデータベースIOから60秒以内に発生する場合、cache.ramから前回のデータが単純に取り出されます。

``cache select``:inxx
``
def cache_db_select():
    logs = db().select(db.log.ALL, cache=(cache.ram, 60))
    return dict(logs=logs)
``:code

-------
selectの結果は複雑で、pickle化できないオブジェクトです。したがって、これらはsessionに保存することはできず、ここで説明したもの以外はどの方法でもキャッシュすることはできません。
-------

### 自己参照と別名

自分自身を参照するフィールドを持つテーブルを定義することも可能ですが、通常の表記方法ではうまくいきません。次のコードは。``db.person``変数を定義する前に用いているので間違っています：
``
db.define_table('person',
    Field('name'),
    Field('father_id', db.person),
    Field('mother_id', db.person))
``:code

解決策は次のような代替表記を使用することです
``
db.define_table('person',
    Field('name'),
    Field('father_id', 'reference person'),
    Field('mother_id', 'reference person'))
``:code

実際、``db.tablename``と``"reference tablename"``は同じフィールドの型になります。

テーブルが自分自身を参照する場合、SQLの"AS"キーワードの使用なしに、JOINを実行して、personとその親(parents)を選択することは不可能です。これは、web2pyにおいて``with_alias``を用いて実現されます。以下がその例です。
``
>>> Father = db.person.with_alias('father')
>>> Mother = db.person.with_alias('mother')
>>> db.person.insert(name='Massimo')
1
>>> db.person.insert(name='Claudia')
2
>>> db.person.insert(name='Marco', father_id=1, mother_id=2)
3
>>> rows = db().select(db.person.name, Father.name, Mother.name,
      left=(Father.on(Father.id==db.person.father_id),
            Mother.on(Mother.id==db.person.mother_id)))
>>> for row in rows:
        print row.person.name, row.father.name, row.mother.name
Massimo None None
Claudia None None
Marco Massimo Claudia
``:code

以下のものを区別して選択していることに注意してください：
- "father_id": "person"テーブルにおいて使用されるフィールド名
- "father": 上記のフィールドによって参照されるテーブルのために使用する別名。これはデータベースとやり取りされます。
- "Father": その別名を参照するためのweb2pyによって使用される変数

違いは僅かで、それら3つに同じ名前をつけても間違いではありません：
``
db.define_table('person',
    Field('name'),
    Field('father', 'reference person'),
    Field('mother', 'reference person'))
>>> father = db.person.with_alias('father')
>>> mother = db.person.with_alias('mother')
>>> db.person.insert(name='Massimo')
1
>>> db.person.insert(name='Claudia')
2
>>> db.person.insert(name='Marco', father=1, mother=2)
3
>>> rows = db().select(db.person.name, father.name, mother.name,
      left=(father.on(father.id==db.person.father),
            mother.on(mother.id==db.person.mother)))
>>> for row in rows:
        print row.person.name, row.father.name, row.mother.name
Massimo None None
Claudia None None
Marco Massimo Claudia
``:code

しかし、正しいクエリを構築するには、この区別を明確にすることが重要です。

### テーブル継承
``inheritance``:inxx

他のテーブルのすべてのフィールドを含んだテーブルを作成することが可能です。これは、他のテーブルを``define_table``に置くだけで十分です。たとえば次のようになります。
``
db.define_table('person', Field('name'))
db.define_table('doctor', db.person, Field('specialization'))
``:code

データベースに保存されないダミーテーブルを定義して、他の複数の場所で再利用することも可能です。例:

``
signature = db.Table(db, 'signature',
    Field('created_on', 'datetime', default=request.now),
    Field('created_by', db.auth_user, default=auth.user_id),
    Field('updated_on', 'datetime', update=request.now),
    Field('updated_by', db.auth_user, update=auth.user_id))

db.define_table('payment', signature, Field('amount', 'double'))
``:code

この例は、標準のweb2py認証が有効になっていることを前提としています。
